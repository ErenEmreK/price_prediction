{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from get_data_yf import get_symbols, get_symbols_sample\n",
    "import os\n",
    "\n",
    "#TODO Change filepaths using os.pathjoint to avoid os dependency if you find time\n",
    "\n",
    "RECOMMENDATION_WEIGHTS = [2, 1, 0, -1, -2] #weights for strongBuy, buy, hold, sell,\tstrongSell advisors respectively\n",
    "TIMEZONE_WEIGHTS = [4, 3, 2, 1] # weights for 0, -1, -2, -3rd months respectively\n",
    "ADVICE_COUNT = 50 #how many of best scored symbols we want to get data\n",
    "folder = 'data/recommendations'\n",
    "recommendation_data_folder = 'data/recommendation_data'\n",
    "\n",
    "score_filename = 'scores.xlsx'\n",
    "recommendations_filename = 'recommendations.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weigth_kernel(vertical_weights, horizontal_weights):\n",
    "    kernel_values = np.outer(vertical_weights, horizontal_weights)\n",
    "    kernel = pd.DataFrame(kernel_values)\n",
    "    kernel.rename(columns={0:'strongBuy', 1:'buy', 2:'hold', \n",
    "                              3:'sell', 4:'strongSell'}, inplace = True)\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_score(recommendations, weight_kernel):\n",
    "    #returns score and how many anaylst we have as advisor in total\n",
    "    sum = recommendations.to_numpy().sum()\n",
    "    if sum == 0:\n",
    "        return None, None\n",
    "    weighted_sum = (weight_kernel * recommendations).to_numpy().sum()\n",
    "    return weighted_sum / sum, sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_symbols(symbols, timezone_weights, recommendation_weights):\n",
    "    #Will return a df that stores scores and advisor count for a symbol\n",
    "    scores = {}\n",
    "    weight_kernel = create_weigth_kernel(timezone_weights, recommendation_weights)\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        recommendations = yf.Ticker(symbol).recommendations\n",
    "        if  recommendations.empty:\n",
    "            print(f\"Couldn't fetch data for {symbol}.\")\n",
    "            continue\n",
    "        \n",
    "        recommendations = recommendations.drop('period', axis='columns')\n",
    "        score, advisor = recommendation_score(recommendations, weight_kernel)\n",
    "        if score:  \n",
    "            scores[symbol] = [score, advisor]\n",
    "        else: \n",
    "            print(f\"No advisors found for {symbol}.\") \n",
    "            \n",
    "    scores_df = pd.DataFrame.from_dict(scores, orient='index', columns=['Scores', 'Advisors'])\n",
    "    scores_df = scores_df.sort_values(by='Scores', ascending=False)\n",
    "    \n",
    "    return scores_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_files(recommendation_data_folder, timezone_weights, recommendation_weights):\n",
    "    scores = {}\n",
    "    weight_kernel = create_weigth_kernel(timezone_weights, recommendation_weights)\n",
    "    \n",
    "    files = os.listdir(recommendation_data_folder)\n",
    "    for filename in files:\n",
    "        if filename.endswith('.csv'):\n",
    "            recommendations = pd.read_csv(f'{recommendation_data_folder}/{filename}')\n",
    "            recommendations = recommendations.drop('period', axis='columns')\n",
    "            \n",
    "            score, advisor = recommendation_score(recommendations, weight_kernel)\n",
    "            symbol = os.path.splitext(filename)[0]\n",
    "            \n",
    "            if score:  \n",
    "                scores[symbol] = [score, advisor]\n",
    "            else: \n",
    "                print(f\"No advisors found for {symbol}.\")\n",
    "    \n",
    "    scores_df = pd.DataFrame.from_dict(scores, orient='index', columns=['Scores', 'Advisors'])\n",
    "    scores_df = scores_df.sort_values(by='Scores', ascending=False)\n",
    "    \n",
    "    return scores_df \n",
    "\n",
    "scores_df = evaluate_files(recommendation_data_folder, TIMEZONE_WEIGHTS, RECOMMENDATION_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_recommendations(scores, folder, score_filename, recommendations_filename, advice_count=10):\n",
    "    with pd.ExcelWriter(f'{folder}/{score_filename}', engine='xlsxwriter') as writer:\n",
    "        scores.to_excel(writer)\n",
    "        print(\"Score file saved.\")\n",
    "        \n",
    "    wanted_symbols = scores.head(advice_count).index.tolist()\n",
    "    with pd.ExcelWriter(f'{folder}/{recommendations_filename}', engine='xlsxwriter') as writer:\n",
    "        starting_row = 0\n",
    "        for symbol in wanted_symbols:\n",
    "            recommendation = yf.Ticker(symbol).recommendations\n",
    "            if not recommendation.empty:\n",
    "                recommendation.to_excel(writer, startrow=starting_row)\n",
    "                writer.sheets['Sheet1'].write(starting_row, 0, symbol)\n",
    "                starting_row += len(recommendation) + 3\n",
    "            else: \n",
    "                print(f\"Couldn't write the recommendations for {symbol}.\")\n",
    "        print(\"Recommendation file saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_wo_data():\n",
    "    #This is the main function to get files without recommendation dfs being \n",
    "    #present at the moment, it calls API for every symbol, so if we have too big\n",
    "    #symbol list, it may trigger API limit. Use main_w_data if you have \n",
    "    #recommendation files in your hand\n",
    "    symbols = get_symbols_sample() #Change this with get_symbols() when you want real -big- set\n",
    "    scores = evaluate_symbols(symbols, TIMEZONE_WEIGHTS, RECOMMENDATION_WEIGHTS)\n",
    "    write_recommendations(scores, folder, score_filename, recommendations_filename, ADVICE_COUNT)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_w_data():\n",
    "    scores = evaluate_files(recommendation_data_folder, TIMEZONE_WEIGHTS, RECOMMENDATION_WEIGHTS)\n",
    "    write_recommendations(scores, folder, score_filename, recommendations_filename, ADVICE_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'to_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(symbols)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#TODO GET ALL\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mget_symbols\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36mget_symbols\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_symbols\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#TODO get all available symbols from yahoo/ listing_status.csv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m#TODO save symbols to reduce api usage\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#TODO get only listed symbols\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/listing_status.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     symbols \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msymbol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(symbols)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'generator' object has no attribute 'to_list'"
     ]
    }
   ],
   "source": [
    "def get_symbols():\n",
    "    #TODO get all available symbols from yahoo/ listing_status.csv\n",
    "    #TODO save symbols to reduce api usage\n",
    "    #TODO get only listed symbols\n",
    "    \n",
    "    df = pd.read_csv('data/listing_status.csv')\n",
    "    symbols = df[['symbol']].items().to_list()\n",
    "    print(symbols)\n",
    "    \n",
    "    #TODO GET ALL\n",
    "get_symbols()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
